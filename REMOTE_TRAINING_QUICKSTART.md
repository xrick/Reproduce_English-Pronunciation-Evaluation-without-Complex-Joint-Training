# Remote NVIDIA GPU Training - Quick Start

## ğŸš€ å¿«é€Ÿé–‹å§‹ï¼ˆ3 æ­¥é©Ÿï¼‰

### 1. æª¢æŸ¥ç’°å¢ƒ
```bash
# ç¢ºèª CUDA å¯ç”¨
nvidia-smi

# ç¢ºèª PyTorch CUDA æ”¯æŒ
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### 2. å•Ÿå‹•è¨“ç·´
```bash
# æ¿€æ´»è™›æ“¬ç’°å¢ƒï¼ˆèˆ‡æœ¬åœ°ç›¸åŒï¼‰
source venv/bin/activate

# è«–æ–‡é…ç½® (r=64) - å–® GPU
python src/train_single_config_remote.py --config paper_r64 --gpus 0

# é è¨“ç·´é…ç½® (r=320) - å–® GPU
python src/train_single_config_remote.py --config pretrained_r320 --gpus 0

# å¤š GPU è¨“ç·´
python src/train_single_config_remote.py --config paper_r64 --gpus 0,1,2,3
```

### 3. ç›£æ§é€²åº¦
```bash
# å¯¦æ™‚ç›£æ§ GPU
watch -n 1 nvidia-smi

# TensorBoard å¯è¦–åŒ–
tensorboard --logdir output/paper_r64/logs
```

## ğŸ“Š é—œéµå·®ç•°ï¼ˆvs Mac æœ¬åœ°è¨“ç·´ï¼‰

| é …ç›® | Mac ç‰ˆæœ¬ | Remote ç‰ˆæœ¬ |
|------|----------|-------------|
| è…³æœ¬æ–‡ä»¶ | `train_single_config.py` | `train_single_config_remote.py` |
| è¨­å‚™ | MPS | CUDA |
| GPU åƒæ•¸ | ç„¡ | `--gpus 0,1,2,3` |
| Pin Memory | âŒ | âœ… |
| å¤šç·šç¨‹åŠ è¼‰ | å–®ç·šç¨‹ | 4 workers |
| å¤š GPU | âŒ | âœ… DDP/FSDP |

## âš™ï¸ å¸¸ç”¨å‘½ä»¤

### åŸºæœ¬è¨“ç·´
```bash
# è«–æ–‡é…ç½®ï¼ˆå¾é›¶è¨“ç·´ r=64ï¼‰
python src/train_single_config_remote.py --config paper_r64 --gpus 0

# é è¨“ç·´é…ç½®ï¼ˆç¹¼çºŒè¨“ç·´ r=320ï¼‰
python src/train_single_config_remote.py --config pretrained_r320 --gpus 0
```

### è‡ªå®šç¾©åƒæ•¸
```bash
python src/train_single_config_remote.py \
  --config paper_r64 \
  --gpus 0,1 \
  --epochs 5 \
  --batch-size 16 \
  --learning-rate 3e-5
```

### FP16 æ¨¡å¼ï¼ˆè¼ƒèˆŠ GPUï¼‰
```bash
# å¦‚æœ GPU ä¸æ”¯æŒ BF16ï¼ˆå¦‚ V100ï¼‰
python src/train_single_config_remote.py --config paper_r64 --gpus 0 --fp16
```

## ğŸ”§ GPU è¨˜æ†¶é«”èª¿æ•´

| GPU å‹è™Ÿ | å…§å­˜ | æ‰¹æ¬¡å¤§å° | æ¢¯åº¦ç´¯ç© |
|---------|------|---------|---------|
| RTX 3090 | 24GB | 4-8 | 8-16 |
| A100 (40GB) | 40GB | 8-16 | 4-8 |
| A100 (80GB) | 80GB | 16-32 | 2-4 |
| V100 | 32GB | 4-8 | 8-16 |

**è¨˜æ†¶é«”ä¸è¶³æ™‚**:
```bash
# æ¸›å°æ‰¹æ¬¡å¤§å°ï¼Œå¢åŠ æ¢¯åº¦ç´¯ç©
python src/train_single_config_remote.py --config paper_r64 --batch-size 4 --gradient-accumulation 16
```

## ğŸ“ è¼¸å‡ºç›®éŒ„

```
output/
â”œâ”€â”€ paper_r64/
â”‚   â”œâ”€â”€ checkpoint-40/          # Epoch 1
â”‚   â”œâ”€â”€ checkpoint-80/          # Epoch 2
â”‚   â”œâ”€â”€ checkpoint-120/         # Epoch 3
â”‚   â”œâ”€â”€ final_model/            # æœ€çµ‚æ¨¡å‹
â”‚   â”œâ”€â”€ logs/                   # TensorBoard
â”‚   â””â”€â”€ training_config_remote.json
```

## â±ï¸ é æœŸè¨“ç·´æ™‚é–“

åŸºæ–¼ 2500 æ¨£æœ¬ï¼Œ3 epochs:

- **RTX 3090**: 8-10 å°æ™‚
- **A100 (40GB)**: 4-6 å°æ™‚
- **A100 (80GB)**: 2-3 å°æ™‚
- **4Ã—A100 (DDP)**: 1-2 å°æ™‚

## ğŸ› å¸¸è¦‹å•é¡Œ

### Q: CUDA out of memory
```bash
# è§£æ±ºæ–¹æ¡ˆï¼šæ¸›å°æ‰¹æ¬¡å¤§å°
--batch-size 4 --gradient-accumulation 16
```

### Q: GPU ä¸æ”¯æŒ BF16
```bash
# è§£æ±ºæ–¹æ¡ˆï¼šä½¿ç”¨ FP16ï¼ˆè…³æœ¬è‡ªå‹•æª¢æ¸¬ï¼Œæˆ–æ‰‹å‹•æŒ‡å®šï¼‰
--fp16
```

### Q: è¨“ç·´ä¸­æ–·å¦‚ä½•æ¢å¾©ï¼Ÿ
```bash
# å¾æœ€å¾Œä¸€å€‹æª¢æŸ¥é»æ¢å¾©
python src/train_single_config_remote.py --config paper_r64 --resume-from-checkpoint output/paper_r64/checkpoint-80
```

## ğŸ“š è©³ç´°æ–‡æª”

å®Œæ•´æŒ‡å—: [claudedocs/remote_training_guide.md](claudedocs/remote_training_guide.md)

åŒ…å«:
- âœ… å¹³å°å·®ç•°è©³è§£
- âœ… DeepSpeed/FSDP é…ç½®
- âœ… å¤šç¯€é»è¨“ç·´
- âœ… æ€§èƒ½å„ªåŒ–å»ºè­°
- âœ… æ•…éšœæ’é™¤æŒ‡å—

## âœ… é·ç§»æ¸…å–®

å¾ Mac é·ç§»åˆ° Remote:

- [ ] è™›æ“¬ç’°å¢ƒå·²æ¿€æ´»
- [ ] CUDA å¯ç”¨ (`nvidia-smi`)
- [ ] ä½¿ç”¨ `train_single_config_remote.py`
- [ ] è¨­ç½® GPU ID (`--gpus`)
- [ ] ç¢ºèª GPU å…§å­˜è¶³å¤ 
- [ ] æ•¸æ“šé›†è·¯å¾‘æ­£ç¢º

å®Œæˆå¾Œå³å¯é–‹å§‹è¨“ç·´ï¼ğŸ‰
