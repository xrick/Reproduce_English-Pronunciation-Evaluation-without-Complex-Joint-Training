#!/usr/bin/env python3
"""
å–®ä¸€é…ç½®è¨“ç·´è…³æœ¬ - Remote NVIDIA GPU ç‰ˆæœ¬
ä½¿ç”¨æ–¹å¼ï¼š
    python train_single_config_remote.py --config pretrained_r320
    python train_single_config_remote.py --config paper_r64 --gpus 0,1

ä¸»è¦å·®ç•°ï¼š
  - CUDA è¨­å‚™æ”¯æŒï¼ˆvs Mac MPSï¼‰
  - å¤š GPU è¨“ç·´æ”¯æŒ
  - å„ªåŒ–çš„ CUDA å…§å­˜ç®¡ç†
  - DeepSpeed/FSDP æ”¯æŒé¸é …
"""

import argparse
import json
import os
import sys
import torch
from transformers import TrainingArguments
from data_utility import get_processed_dataset
from model_utility_configs import CONFIGS
from AudioDataCollator import AudioDataCollator


def main():
    parser = argparse.ArgumentParser(description="è¨“ç·´å–®ä¸€ LoRA é…ç½®ï¼ˆRemote NVIDIA GPUï¼‰")
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        choices=["pretrained_r320", "paper_r64"],
        help="é¸æ“‡é…ç½®: pretrained_r320 æˆ– paper_r64"
    )
    parser.add_argument(
        "--train-data",
        type=str,
        default="../../DataSets/Reproduce_English_Pronunciation/speechocean762_formatted/train/",
        help="è¨“ç·´æ•¸æ“šé›†è·¯å¾‘"
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=3,
        help="è¨“ç·´ epoch æ•¸ï¼ˆè«–æ–‡å»ºè­° 3ï¼‰"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=8,
        help="æ¯å€‹è¨­å‚™çš„æ‰¹æ¬¡å¤§å°ï¼ˆè«–æ–‡è¨­å®š 8ï¼‰"
    )
    parser.add_argument(
        "--gradient-accumulation",
        type=int,
        default=8,
        help="æ¢¯åº¦ç´¯ç©æ­¥æ•¸ï¼ˆè«–æ–‡è¨­å®š 8ï¼‰"
    )
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=2e-5,
        help="å­¸ç¿’ç‡ï¼ˆè«–æ–‡è¨­å®š 2e-5ï¼‰"
    )
    parser.add_argument(
        "--gpus",
        type=str,
        default="0",
        help="ä½¿ç”¨çš„ GPU IDï¼ˆé€—è™Ÿåˆ†éš”ï¼Œä¾‹å¦‚: 0,1,2,3ï¼‰"
    )
    parser.add_argument(
        "--fp16",
        action="store_true",
        help="ä½¿ç”¨ FP16 æ··åˆç²¾åº¦ï¼ˆå¦‚æœ GPU ä¸æ”¯æŒ BF16ï¼‰"
    )
    parser.add_argument(
        "--deepspeed",
        type=str,
        default=None,
        help="DeepSpeed é…ç½®æ–‡ä»¶è·¯å¾‘ï¼ˆå¯é¸ï¼‰"
    )
    parser.add_argument(
        "--fsdp",
        action="store_true",
        help="å•Ÿç”¨ FSDPï¼ˆFully Sharded Data Parallelï¼‰"
    )

    args = parser.parse_args()

    # è¨­ç½® CUDA å¯è¦‹è¨­å‚™
    os.environ["CUDA_VISIBLE_DEVICES"] = args.gpus
    gpu_ids = [int(x) for x in args.gpus.split(",")]
    num_gpus = len(gpu_ids)

    print("\n" + "="*80)
    print(f"ğŸ–¥ï¸  Remote Training Configuration")
    print("="*80)
    print(f"è¨“ç·´é…ç½®: {args.config}")
    print(f"GPU è¨­å‚™: {args.gpus} ({num_gpus} GPU(s))")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        for i in range(num_gpus):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"  å…§å­˜: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB")
    print("="*80)

    # ç²å–é…ç½®
    config = CONFIGS[args.config]
    print(f"\næè¿°: {config['description']}")

    # è¼‰å…¥æ¨¡å‹
    print(f"\nè¼‰å…¥æ¨¡å‹...")
    model, processor, peft_config = config["loader"]()

    # è¼‰å…¥æ•¸æ“šé›†
    print(f"\nè¼‰å…¥è¨“ç·´æ•¸æ“šé›†: {args.train_data}")
    train_data = get_processed_dataset(args.train_data)
    print(f"è¨“ç·´æ¨£æœ¬æ•¸: {len(train_data)}")

    # è¨­ç½®è¼¸å‡ºç›®éŒ„
    output_dir = config["output_dir"]
    os.makedirs(output_dir, exist_ok=True)

    # ç¢ºå®šç²¾åº¦è¨­ç½®
    use_bf16 = not args.fp16
    use_fp16 = args.fp16

    # æª¢æŸ¥ BF16 æ”¯æŒ
    if use_bf16 and torch.cuda.is_available():
        # æª¢æŸ¥ GPU æ˜¯å¦æ”¯æŒ BF16ï¼ˆéœ€è¦ Ampere æ¶æ§‹æˆ–æ›´æ–°ï¼‰
        compute_capability = torch.cuda.get_device_capability()
        if compute_capability[0] < 8:  # Ampere is 8.x
            print(f"âš ï¸  è­¦å‘Š: GPU è¨ˆç®—èƒ½åŠ› {compute_capability} ä¸æ”¯æŒ BF16ï¼Œåˆ‡æ›åˆ° FP16")
            use_bf16 = False
            use_fp16 = True

    # è¨“ç·´åƒæ•¸ï¼ˆé‡å° NVIDIA GPU å„ªåŒ–ï¼‰
    training_args_dict = {
        "output_dir": output_dir,

        # è«–æ–‡è¶…åƒæ•¸
        "num_train_epochs": args.epochs,
        "per_device_train_batch_size": args.batch_size,
        "gradient_accumulation_steps": args.gradient_accumulation,
        "learning_rate": args.learning_rate,

        # å„ªåŒ–å™¨å’Œç²¾åº¦
        "optim": "adamw_torch",
        "bf16": use_bf16,
        "fp16": use_fp16,

        # æ—¥èªŒå’Œä¿å­˜
        "logging_steps": 10,
        "logging_dir": f"{output_dir}/logs",
        "save_strategy": "epoch",
        "save_total_limit": 3,

        # è©•ä¼°
        "eval_strategy": "no",

        # å…¶ä»–
        "report_to": "tensorboard",

        # å…§å­˜å„ªåŒ–
        "gradient_checkpointing": True,

        # æ•¸æ“šè™•ç† - ä¿ç•™æ‰€æœ‰æ¬„ä½çµ¦ AudioDataCollator
        "remove_unused_columns": False,

        # CUDA å„ªåŒ–
        "dataloader_pin_memory": True,  # CUDA æ”¯æŒ pin memory
        "dataloader_num_workers": 4,     # å¤šç·šç¨‹æ•¸æ“šåŠ è¼‰
    }

    # å¤š GPU è¨­ç½®
    if num_gpus > 1:
        training_args_dict["ddp_find_unused_parameters"] = False
        print(f"\nğŸš€ å•Ÿç”¨å¤š GPU è¨“ç·´ ({num_gpus} GPUs)")

    # DeepSpeed é…ç½®
    if args.deepspeed:
        training_args_dict["deepspeed"] = args.deepspeed
        print(f"\nâš¡ å•Ÿç”¨ DeepSpeed: {args.deepspeed}")

    # FSDP é…ç½®
    if args.fsdp and num_gpus > 1:
        training_args_dict["fsdp"] = "full_shard auto_wrap"
        training_args_dict["fsdp_transformer_layer_cls_to_wrap"] = "Phi4MMDecoderLayer"
        print(f"\nğŸ”§ å•Ÿç”¨ FSDP (Fully Sharded Data Parallel)")

    training_args = TrainingArguments(**training_args_dict)

    # å‰µå»º Trainer
    from transformers import Trainer

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_data,
        data_collator=AudioDataCollator(processor),
    )

    # ä¿å­˜é…ç½®ä¿¡æ¯
    config_info = {
        "config_name": args.config,
        "description": config["description"],
        "speech_lora": config["speech_lora"],
        "vision_lora": config["vision_lora"],
        "trainable_params": config["trainable_params"],
        "training_args": {
            "num_train_epochs": args.epochs,
            "per_device_train_batch_size": args.batch_size,
            "gradient_accumulation_steps": args.gradient_accumulation,
            "learning_rate": args.learning_rate,
            "effective_batch_size": args.batch_size * args.gradient_accumulation * num_gpus,
            "num_gpus": num_gpus,
            "precision": "bf16" if use_bf16 else "fp16",
        },
        "hardware": {
            "cuda_version": torch.version.cuda if torch.cuda.is_available() else "N/A",
            "num_gpus": num_gpus,
            "gpu_names": [torch.cuda.get_device_name(i) for i in range(num_gpus)] if torch.cuda.is_available() else [],
        }
    }

    config_info_path = os.path.join(output_dir, "training_config_remote.json")
    with open(config_info_path, "w", encoding="utf-8") as f:
        json.dump(config_info, f, indent=2, ensure_ascii=False)

    print(f"\nè¨“ç·´é…ç½®å·²ä¿å­˜è‡³: {config_info_path}")
    print(f"è¼¸å‡ºç›®éŒ„: {output_dir}")
    print(f"è¨“ç·´åƒæ•¸: {config['trainable_params']}")
    print(f"æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {args.batch_size * args.gradient_accumulation * num_gpus}")
    print(f"ç²¾åº¦: {'BF16' if use_bf16 else 'FP16'}")

    # é–‹å§‹è¨“ç·´
    print(f"\nğŸš€ é–‹å§‹è¨“ç·´...")
    print("="*80 + "\n")
    trainer.train()

    # ä¿å­˜æœ€çµ‚æ¨¡å‹
    final_model_dir = f"{output_dir}/final_model"
    print(f"\nğŸ’¾ ä¿å­˜æœ€çµ‚æ¨¡å‹è‡³: {final_model_dir}")
    trainer.save_model(final_model_dir)

    # ä¿å­˜è™•ç†å™¨
    processor.save_pretrained(final_model_dir)

    print(f"\nâœ… è¨“ç·´å®Œæˆï¼")
    print(f"æ¨¡å‹ä¿å­˜ä½ç½®: {final_model_dir}")
    print(f"TensorBoard æ—¥èªŒ: {output_dir}/logs")
    print("\nå»ºè­°ä¸‹ä¸€æ­¥:")
    print(f"  tensorboard --logdir {output_dir}/logs")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
