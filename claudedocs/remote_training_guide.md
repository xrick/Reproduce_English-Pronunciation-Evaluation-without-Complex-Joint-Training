# Remote NVIDIA GPU Training Guide

å®Œæ•´çš„é ç¨‹ NVIDIA GPU è¨“ç·´æŒ‡å—

## å¹³å°å·®ç•°ç¸½çµ

| ç‰¹æ€§ | Mac (Apple Silicon) | Remote (NVIDIA GPU) |
|------|---------------------|---------------------|
| è¨­å‚™ | `mps` | `cuda` |
| Pin Memory | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| æ··åˆç²¾åº¦ | BF16 | BF16/FP16ï¼ˆè¦– GPU æ¶æ§‹ï¼‰ |
| å¤š GPU | âŒ å–®è¨­å‚™ | âœ… DDP/FSDP/DeepSpeed |
| æ•¸æ“šåŠ è¼‰ | å–®ç·šç¨‹ | å¤šç·šç¨‹ï¼ˆ4 workersï¼‰ |
| å…§å­˜å„ªåŒ– | MPS è‡ªå‹•ç®¡ç† | CUDA ç·©å­˜ç®¡ç† |

## æ–‡ä»¶å°æ¯”

### æœ¬åœ°è¨“ç·´ï¼ˆMacï¼‰
```bash
python train_single_config.py --config paper_r64
```
**æ–‡ä»¶**: `src/train_single_config.py`

### é ç¨‹è¨“ç·´ï¼ˆNVIDIAï¼‰
```bash
python train_single_config_remote.py --config paper_r64
```
**æ–‡ä»¶**: `src/train_single_config_remote.py`

## é—œéµå·®ç•°

### 1. è¨­å‚™æª¢æ¸¬å’Œåˆ†é…

**Mac ç‰ˆæœ¬**:
```python
# è‡ªå‹•ä½¿ç”¨ MPSï¼ˆApple Metal Performance Shadersï¼‰
# ç„¡éœ€æ‰‹å‹•è¨­ç½®è¨­å‚™
```

**Remote ç‰ˆæœ¬**:
```python
# æ˜ç¢ºè¨­ç½® CUDA è¨­å‚™
os.environ["CUDA_VISIBLE_DEVICES"] = args.gpus
# æª¢æŸ¥ CUDA å¯ç”¨æ€§
if torch.cuda.is_available():
    print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
```

### 2. æ··åˆç²¾åº¦æ”¯æŒ

**Mac ç‰ˆæœ¬**:
```python
training_args = TrainingArguments(
    bf16=True,  # MPS æ”¯æŒ BF16
)
```

**Remote ç‰ˆæœ¬**:
```python
# è‡ªå‹•æª¢æ¸¬ GPU æ¶æ§‹
compute_capability = torch.cuda.get_device_capability()
if compute_capability[0] < 8:  # Ampere ä¹‹å‰çš„æ¶æ§‹
    use_fp16 = True  # ä½¿ç”¨ FP16
else:
    use_bf16 = True  # Ampere+ ä½¿ç”¨ BF16

training_args = TrainingArguments(
    bf16=use_bf16,
    fp16=use_fp16,
)
```

### 3. æ•¸æ“šåŠ è¼‰å„ªåŒ–

**Mac ç‰ˆæœ¬**:
```python
training_args = TrainingArguments(
    # MPS ä¸æ”¯æŒ pin_memory
    # æ•¸æ“šåŠ è¼‰å™¨ä½¿ç”¨é»˜èªè¨­ç½®
)
```

**Remote ç‰ˆæœ¬**:
```python
training_args = TrainingArguments(
    dataloader_pin_memory=True,     # CUDA å„ªåŒ–
    dataloader_num_workers=4,       # å¤šç·šç¨‹åŠ è¼‰
)
```

### 4. å¤š GPU æ”¯æŒ

**Remote ç‰ˆæœ¬æ–°å¢åŠŸèƒ½**:

#### å–® GPU
```bash
python train_single_config_remote.py --config paper_r64 --gpus 0
```

#### å¤š GPU (DDP - Distributed Data Parallel)
```bash
python train_single_config_remote.py --config paper_r64 --gpus 0,1,2,3
```

#### FSDP (Fully Sharded Data Parallel)
```bash
python train_single_config_remote.py --config paper_r64 --gpus 0,1,2,3 --fsdp
```

#### DeepSpeed (å…§å­˜æ•ˆç‡æœ€é«˜)
```bash
python train_single_config_remote.py --config paper_r64 --gpus 0,1,2,3 --deepspeed ds_config.json
```

## ä½¿ç”¨æ–¹å¼

### åŸºæœ¬è¨“ç·´ï¼ˆå–® GPUï¼‰

```bash
# è«–æ–‡é…ç½® (r=64)
python train_single_config_remote.py --config paper_r64 --gpus 0

# é è¨“ç·´é…ç½® (r=320)
python train_single_config_remote.py --config pretrained_r320 --gpus 0
```

### å¤š GPU è¨“ç·´

```bash
# ä½¿ç”¨ 4 å€‹ GPU
python train_single_config_remote.py --config paper_r64 --gpus 0,1,2,3
```

### è‡ªå®šç¾©è¶…åƒæ•¸

```bash
python train_single_config_remote.py \
  --config paper_r64 \
  --gpus 0,1 \
  --epochs 5 \
  --batch-size 16 \
  --gradient-accumulation 4 \
  --learning-rate 3e-5
```

### ä½¿ç”¨ FP16ï¼ˆè¼ƒèˆŠ GPUï¼‰

```bash
# å¦‚æœ GPU ä¸æ”¯æŒ BF16ï¼ˆå¦‚ V100ï¼‰
python train_single_config_remote.py --config paper_r64 --gpus 0 --fp16
```

## GPU æ¶æ§‹æ”¯æŒ

### BF16 æ”¯æŒï¼ˆæ¨è–¦ï¼‰
- âœ… A100 (Compute Capability 8.0)
- âœ… A6000 (Compute Capability 8.6)
- âœ… RTX 3090/4090 (Compute Capability 8.6/8.9)
- âœ… H100 (Compute Capability 9.0)

### FP16 æ”¯æŒï¼ˆå‚™é¸ï¼‰
- âœ… V100 (Compute Capability 7.0)
- âœ… P100 (Compute Capability 6.0)
- âœ… æ‰€æœ‰ NVIDIA GPU

**æª¢æŸ¥æ–¹æ³•**:
```python
import torch
print(torch.cuda.get_device_capability())
# (8, 0) = A100 â†’ æ”¯æŒ BF16
# (7, 0) = V100 â†’ åƒ…æ”¯æŒ FP16
```

## DeepSpeed é…ç½®ï¼ˆå¯é¸ï¼‰

å¦‚æœéœ€è¦æœ€å¤§åŒ–å…§å­˜æ•ˆç‡ï¼Œå‰µå»º `ds_config.json`:

```json
{
  "train_batch_size": "auto",
  "train_micro_batch_size_per_gpu": "auto",
  "gradient_accumulation_steps": "auto",
  "gradient_clipping": 1.0,
  "zero_optimization": {
    "stage": 2,
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "allgather_partitions": true,
    "allgather_bucket_size": 2e8,
    "reduce_scatter": true,
    "reduce_bucket_size": 2e8,
    "overlap_comm": true,
    "contiguous_gradients": true
  },
  "fp16": {
    "enabled": false
  },
  "bf16": {
    "enabled": true
  },
  "optimizer": {
    "type": "AdamW",
    "params": {
      "lr": "auto",
      "betas": "auto",
      "eps": "auto",
      "weight_decay": "auto"
    }
  },
  "scheduler": {
    "type": "WarmupLR",
    "params": {
      "warmup_min_lr": "auto",
      "warmup_max_lr": "auto",
      "warmup_num_steps": "auto"
    }
  }
}
```

ä½¿ç”¨æ–¹å¼:
```bash
python train_single_config_remote.py --config paper_r64 --gpus 0,1,2,3 --deepspeed ds_config.json
```

## æ€§èƒ½å„ªåŒ–å»ºè­°

### æ‰¹æ¬¡å¤§å°èª¿æ•´

æ ¹æ“š GPU å…§å­˜èª¿æ•´:

| GPU å‹è™Ÿ | å…§å­˜ | å»ºè­°æ‰¹æ¬¡å¤§å° | æ¢¯åº¦ç´¯ç© |
|---------|------|------------|---------|
| RTX 3090 | 24GB | 4-8 | 8-16 |
| A100 (40GB) | 40GB | 8-16 | 4-8 |
| A100 (80GB) | 80GB | 16-32 | 2-4 |
| V100 | 32GB | 4-8 | 8-16 |

**è¨ˆç®—å…¬å¼**:
```
æœ‰æ•ˆæ‰¹æ¬¡å¤§å° = æ‰¹æ¬¡å¤§å° Ã— æ¢¯åº¦ç´¯ç© Ã— GPU æ•¸é‡
è«–æ–‡è¨­å®š = 8 Ã— 8 Ã— 1 = 64
```

### æ•¸æ“šåŠ è¼‰å„ªåŒ–

```python
# æ ¹æ“š CPU æ ¸å¿ƒæ•¸èª¿æ•´
dataloader_num_workers = min(4, os.cpu_count())
```

### å…§å­˜ä¸è¶³ï¼ˆOOMï¼‰è§£æ±ºæ–¹æ¡ˆ

1. **æ¸›å°æ‰¹æ¬¡å¤§å°**:
```bash
python train_single_config_remote.py --config paper_r64 --batch-size 4 --gradient-accumulation 16
```

2. **å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»**ï¼ˆå·²é»˜èªå•Ÿç”¨ï¼‰:
```python
gradient_checkpointing=True
```

3. **ä½¿ç”¨ DeepSpeed ZeRO**:
```bash
python train_single_config_remote.py --config paper_r64 --deepspeed ds_config.json
```

## ç›£æ§å’Œèª¿è©¦

### å¯¦æ™‚ç›£æ§

```bash
# çµ‚ç«¯ 1: é‹è¡Œè¨“ç·´
python train_single_config_remote.py --config paper_r64 --gpus 0

# çµ‚ç«¯ 2: ç›£æ§ GPU
watch -n 1 nvidia-smi

# çµ‚ç«¯ 3: TensorBoard
tensorboard --logdir output/paper_r64/logs
```

### å¸¸è¦‹è­¦å‘Šå’Œè§£æ±ºæ–¹æ¡ˆ

#### è­¦å‘Š: "pin_memory not supported on MPS"
- **Mac æœ¬åœ°è¨“ç·´**: å¿½ç•¥ï¼ˆæ­£å¸¸ç¾è±¡ï¼‰
- **Remote NVIDIA**: ä¸æ‡‰å‡ºç¾ï¼ˆå·²å•Ÿç”¨ pin_memoryï¼‰

#### éŒ¯èª¤: "CUDA out of memory"
```bash
# è§£æ±ºæ–¹æ¡ˆ 1: æ¸›å°æ‰¹æ¬¡å¤§å°
--batch-size 4 --gradient-accumulation 16

# è§£æ±ºæ–¹æ¡ˆ 2: ä½¿ç”¨ DeepSpeed
--deepspeed ds_config.json
```

#### è­¦å‘Š: "GPU ä¸æ”¯æŒ BF16"
```bash
# è‡ªå‹•åˆ‡æ›åˆ° FP16ï¼ˆè…³æœ¬å·²è™•ç†ï¼‰
# æˆ–æ‰‹å‹•æŒ‡å®š:
--fp16
```

## è¼¸å‡ºçµæ§‹

è¨“ç·´å®Œæˆå¾Œçš„æ–‡ä»¶çµæ§‹:

```
output/
â”œâ”€â”€ paper_r64/
â”‚   â”œâ”€â”€ checkpoint-40/          # Epoch 1 æª¢æŸ¥é»
â”‚   â”œâ”€â”€ checkpoint-80/          # Epoch 2 æª¢æŸ¥é»
â”‚   â”œâ”€â”€ checkpoint-120/         # Epoch 3 æª¢æŸ¥é»
â”‚   â”œâ”€â”€ final_model/            # æœ€çµ‚æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ logs/                   # TensorBoard æ—¥èªŒ
â”‚   â”‚   â””â”€â”€ events.out.tfevents.*
â”‚   â””â”€â”€ training_config_remote.json  # è¨“ç·´é…ç½®è¨˜éŒ„
```

## é·ç§»æ¸…å–®

å¾ Mac é·ç§»åˆ° Remote NVIDIA GPU:

- [x] âœ… ä½¿ç”¨ `train_single_config_remote.py` è€Œé `train_single_config.py`
- [x] âœ… æª¢æŸ¥ CUDA å¯ç”¨æ€§: `nvidia-smi`
- [x] âœ… è¨­ç½®æ­£ç¢ºçš„ GPU ID: `--gpus 0` æˆ– `--gpus 0,1,2,3`
- [x] âœ… ç¢ºèª GPU æ¶æ§‹ï¼ˆBF16 vs FP16ï¼‰
- [x] âœ… æ ¹æ“š GPU å…§å­˜èª¿æ•´æ‰¹æ¬¡å¤§å°
- [x] âœ… è™›æ“¬ç’°å¢ƒç›¸åŒï¼ˆå·²ç¢ºèªï¼‰
- [x] âœ… æ•¸æ“šé›†è·¯å¾‘æ­£ç¢º
- [x] âœ… è¼¸å‡ºç›®éŒ„å¯å¯«

## é æœŸè¨“ç·´æ™‚é–“

åŸºæ–¼è«–æ–‡è¨­å®šï¼ˆ2500 æ¨£æœ¬ï¼Œ3 epochsï¼‰:

| GPU å‹è™Ÿ | æ‰¹æ¬¡å¤§å° | é ä¼°æ™‚é–“ |
|---------|---------|---------|
| RTX 3090 | 8 | 8-10 å°æ™‚ |
| A100 (40GB) | 8 | 4-6 å°æ™‚ |
| A100 (80GB) | 16 | 2-3 å°æ™‚ |
| 4Ã—A100 (DDP) | 8 | 1-2 å°æ™‚ |

## æ•…éšœæ’é™¤

### 1. å°å…¥éŒ¯èª¤
```python
ModuleNotFoundError: No module named 'torch'
```
**è§£æ±º**: ç¢ºèªè™›æ“¬ç’°å¢ƒå·²æ¿€æ´»
```bash
source venv/bin/activate
pip list | grep torch
```

### 2. CUDA ä¸å¯ç”¨
```python
torch.cuda.is_available() = False
```
**æª¢æŸ¥**:
```bash
nvidia-smi
echo $CUDA_VISIBLE_DEVICES
```

### 3. å¤š GPU è¨“ç·´å¤±æ•—
```bash
# ä½¿ç”¨ torchrunï¼ˆæ¨è–¦ï¼‰
torchrun --nproc_per_node=4 train_single_config_remote.py --config paper_r64
```

## é€²éšç”¨æ³•

### æ–·é»çºŒè¨“

```bash
# è¨“ç·´æœƒè‡ªå‹•åœ¨æ¯å€‹ epoch ä¿å­˜æª¢æŸ¥é»
# å¾æª¢æŸ¥é»æ¢å¾©:
python train_single_config_remote.py --config paper_r64 --resume-from-checkpoint output/paper_r64/checkpoint-80
```

### æ··åˆä½¿ç”¨å¤šå°æ©Ÿå™¨

ä½¿ç”¨ `torchrun` çš„å¤šç¯€é»è¨“ç·´ï¼ˆéœ€è¦ SSH é…ç½®ï¼‰:

```bash
# ä¸»ç¯€é»ï¼ˆRank 0ï¼‰
torchrun --nproc_per_node=4 --nnodes=2 --node_rank=0 --master_addr=192.168.1.1 --master_port=29500 train_single_config_remote.py --config paper_r64

# å¾ç¯€é»ï¼ˆRank 1ï¼‰
torchrun --nproc_per_node=4 --nnodes=2 --node_rank=1 --master_addr=192.168.1.1 --master_port=29500 train_single_config_remote.py --config paper_r64
```

## ç¸½çµ

**é—œéµå„ªå‹¢**:
1. âœ… è‡ªå‹•æª¢æ¸¬ GPU æ¶æ§‹å’Œæ··åˆç²¾åº¦æ”¯æŒ
2. âœ… å¤š GPU ä¸¦è¡Œè¨“ç·´ï¼ˆDDP/FSDP/DeepSpeedï¼‰
3. âœ… å„ªåŒ–çš„ CUDA æ•¸æ“šåŠ è¼‰ï¼ˆpin_memory + å¤šç·šç¨‹ï¼‰
4. âœ… éˆæ´»çš„æ‰¹æ¬¡å¤§å°å’Œå…§å­˜ç®¡ç†
5. âœ… å®Œæ•´çš„è¨“ç·´ç›£æ§å’Œæ—¥èªŒè¨˜éŒ„

**æ¨è–¦å·¥ä½œæµ**:
```bash
# 1. æª¢æŸ¥ç’°å¢ƒ
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# 2. é–‹å§‹è¨“ç·´
python train_single_config_remote.py --config paper_r64 --gpus 0

# 3. ç›£æ§é€²åº¦
tensorboard --logdir output/paper_r64/logs
```

ç¥è¨“ç·´é †åˆ©ï¼ğŸš€
